{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline model\n",
    "In this notebook we explore our options for a baseline model. We also look at what preprocessing steps are needed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d132c6f1ea4aa6dd"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:47.125846Z",
     "start_time": "2023-12-05T12:21:47.105111Z"
    }
   },
   "id": "127c712414785d29"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "RANDOM_SEED = 21223"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:47.129395Z",
     "start_time": "2023-12-05T12:21:47.107296Z"
    }
   },
   "id": "4fccdfe32ca19096"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unzip dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f48bdda2c0a82d19"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:47.129849Z",
     "start_time": "2023-12-05T12:21:47.114483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory ../data/asl_train already exists. Skipped unzipping.\n",
      "The directory ../data/asl_test already exists. Skipped unzipping.\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "dir_path = \"../data\"\n",
    "train_path = dir_path + \"/asl_train\"\n",
    "test_path = dir_path + \"/asl_test\"\n",
    "\n",
    "def unzip_if_not_exists(zip_file_path, extract_to_path):\n",
    "    # check if the target directory already exists\n",
    "    if not os.path.exists(extract_to_path):\n",
    "        # create the directory if it doesn't exist\n",
    "        os.makedirs(extract_to_path)\n",
    "        # unzip the contents\n",
    "        with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to_path)\n",
    "        print(f\"Successfully unzipped to {extract_to_path}\")\n",
    "    else:\n",
    "        print(f\"The directory {extract_to_path} already exists. Skipped unzipping.\")\n",
    "\n",
    "unzip_if_not_exists(dir_path + \"/asl_alphabet_train.zip\", train_path)\n",
    "unzip_if_not_exists(dir_path + \"/asl_alphabet_test.zip\", test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Store all data in a pandas df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4905bfaa71d3f05"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_path += \"/asl_alphabet_train/\"\n",
    "test_path += \"/asl_alphabet_test/\"\n",
    "\n",
    "# map alphabet to numbers\n",
    "categories = {  0: \"A\",\n",
    "                1: \"B\",\n",
    "                2: \"C\",\n",
    "                3: \"D\",\n",
    "                4: \"E\",\n",
    "                5: \"F\",\n",
    "                6: \"G\",\n",
    "                7: \"H\",\n",
    "                8: \"I\",\n",
    "                9: \"K\",\n",
    "                10: \"L\",\n",
    "                11: \"M\",\n",
    "                12: \"N\",\n",
    "                13: \"O\",\n",
    "                14: \"P\",\n",
    "                15: \"Q\",\n",
    "                16: \"R\",\n",
    "                17: \"S\",\n",
    "                18: \"T\",\n",
    "                19: \"U\",\n",
    "                20: \"V\",\n",
    "                21: \"W\",\n",
    "                22: \"X\",\n",
    "                23: \"Y\",\n",
    "            }\n",
    "\n",
    "def add_class_name_prefix(df, col_name):\n",
    "    df[col_name]\n",
    "    return df\n",
    "\n",
    "# store all the file names in the dataset\n",
    "filenames = []\n",
    "# store the corresponding class for each file\n",
    "target = []\n",
    "\n",
    "for category in categories:\n",
    "    files = os.listdir(train_path + categories[category])\n",
    "    filenames += files\n",
    "    target += [category] * len(files)\n",
    "\n",
    "df = pd.DataFrame({\"filename\": filenames, \"category\": target})\n",
    "df = add_class_name_prefix(df, \"filename\")\n",
    "\n",
    "# shuffle the dataframe\n",
    "df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:47.358680Z",
     "start_time": "2023-12-05T12:21:47.124306Z"
    }
   },
   "id": "a3cc407b34b5210f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "check it out"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2184f032fabc2aa9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72000 entries, 0 to 71999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   filename  72000 non-null  object\n",
      " 1   category  72000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "    filename  category\n0  V1957.jpg        20\n1  M2695.jpg        11\n2   C705.jpg         2\n3  T1148.jpg        18\n4   P600.jpg        14",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V1957.jpg</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M2695.jpg</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>C705.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>T1148.jpg</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P600.jpg</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:47.388051Z",
     "start_time": "2023-12-05T12:21:47.368328Z"
    }
   },
   "id": "8681b877bfc771dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "sample a smaller dataset. split into train and test."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da7942553b3bcf26"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 2)\n",
      "(480, 2)\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "n_train = int(n*0.8)\n",
    "\n",
    "# sample n random data points from each sign class\n",
    "df_small = df.groupby('category', group_keys=False).apply(lambda x: x.sample(n, ignore_index=True, random_state=RANDOM_SEED))\n",
    "\n",
    "# sample n_train % of the small df for the train set\n",
    "df_train = df.groupby('category', group_keys=False).apply(lambda x: x.sample(n_train, ignore_index=True, random_state=RANDOM_SEED))\n",
    "\n",
    "# shuffle train set\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# obtain test set from remaining points in the small df\n",
    "df_test = pd.merge(df_small, df_train, how='left', indicator=True)\n",
    "df_test = df_test[df_test['_merge'] == 'left_only'].drop(columns=['_merge']).reset_index(drop=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:47.436242Z",
     "start_time": "2023-12-05T12:21:47.388375Z"
    }
   },
   "id": "8f36c13ce1490d86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing steps:\n",
    "- Grayscale\n",
    "- Flatten to 1D\n",
    "- Normalize pixel values to 0-1\n",
    "- Feature extraction/Dimensionality reduction -> TBD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72668d1aca9dfffe"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# preprocess each row in the dataframes\n",
    "def process_row(row):\n",
    "    filename = row[\"filename\"]\n",
    "    label = row[\"category\"]\n",
    "    # load\n",
    "    image = Image.open(train_path + \"/\" + categories[label] + \"/\" + filename)\n",
    "    # convert to grayscale\n",
    "    gray_image = image.convert('L')\n",
    "    # convert to 2d tensor\n",
    "    image_arr = np.array(gray_image)\n",
    "    # normalize to 0-1 range\n",
    "    normalized_arr = image_arr / 255\n",
    "    # flatten 2d tensor to 1d array\n",
    "    flat_image = normalized_arr.ravel()\n",
    "    new_row = {'image_array': flat_image, 'label': label}\n",
    "    return new_row\n",
    "\n",
    "df_train_processed = df_train.apply(process_row, axis=1, result_type=\"expand\")\n",
    "df_test_processed = df_test.apply(process_row, axis=1, result_type=\"expand\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:51.207838Z",
     "start_time": "2023-12-05T12:21:47.424592Z"
    }
   },
   "id": "cd8868e10e78589a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         image_array  label\n0  [0.12549019607843137, 0.13725490196078433, 0.1...     22\n1  [0.11764705882352941, 0.12941176470588237, 0.1...     15",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_array</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.12549019607843137, 0.13725490196078433, 0.1...</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.11764705882352941, 0.12941176470588237, 0.1...</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_processed.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:21:51.220075Z",
     "start_time": "2023-12-05T12:21:51.213348Z"
    }
   },
   "id": "c46e1fc2178fec41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "extract X and y from df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29a2f90a355649b2"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "1920\n",
      "480\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(df_train_processed['image_array'].tolist())\n",
    "y_train = np.array(df_train_processed['label'])\n",
    "\n",
    "X_test = np.array(df_test_processed['image_array'].tolist())\n",
    "y_test = np.array(df_test_processed['label'])\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:25:10.206789Z",
     "start_time": "2023-12-05T12:25:09.371055Z"
    }
   },
   "id": "310d66f5f58f065b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "at this point we have 1D arrays of all 40k pixels for each image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a1de23400ad8d8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "74c9e96eae78515d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-mlp",
   "language": "python",
   "display_name": "conda-mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
